{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To install the required libraries run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports from the standard genepro-multi library are done here. Any adjustments (e.g. different operators) should be made in the notebook. For example:\n",
    "\n",
    "```\n",
    "class SmoothOperator(Node):\n",
    "  def __init__(self):\n",
    "    super(SmoothOperator,self).__init__()\n",
    "    self.arity = 1\n",
    "    self.symb = \"SmoothOperator\"\n",
    "\n",
    "  def _get_args_repr(self, args):\n",
    "    return self._get_typical_repr(args,'before')\n",
    "\n",
    "  def get_output(self, X):\n",
    "    c_outs = self._get_child_outputs(X)\n",
    "    return np.smoothOperation(c_outs[0])\n",
    "\n",
    "  def get_output_pt(self, X):\n",
    "    c_outs = self._get_child_outputs_pt(X)\n",
    "    return torch.smoothOperation(c_outs[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Setup\n",
    "Here we first setup the Gymnasium environment. Please see https://gymnasium.farama.org/environments/box2d/lunar_lander/ for more information on the environment. \n",
    "\n",
    "Then a memory buffer is made. This is a buffer in which state transitions are stored. When the buffer reaches its maximum capacity old transitions are replaced by new ones.\n",
    "\n",
    "A frame buffer is initialised used to later store animation frames of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\"))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        self.memory += other.memory\n",
    "        return self\n",
    "\n",
    "    def __add__(self, other):\n",
    "        self.memory = self.memory + other.memory\n",
    "        return self"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function\n",
    "\n",
    "Here you get to be creative. The default setup evaluates 5 episodes of 300 frames. Think of what action to pick and what fitness function to use. The Multi-tree takes an input of $n \\times d$ where $n$ is a batch of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function_pt(multitree, num_episodes=5, episode_duration=300, ignore_done=False, render=False):\n",
    "    memory = ReplayMemory(10000)\n",
    "    episode_rewards = []\n",
    "    if render:\n",
    "        frames = []\n",
    "\n",
    "    # print(multitree.get_readable_repr())\n",
    "    for _ in range(num_episodes):\n",
    "        # get initial state of the environment\n",
    "        observation = env.reset()\n",
    "        observation = observation[0]\n",
    "        rewards = []\n",
    "        for _ in range(episode_duration):\n",
    "            if render:\n",
    "                frames.append(env.render())\n",
    "            input_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "            action = torch.argmax(multitree.get_output_pt(input_sample)).detach()\n",
    "            observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "            rewards.append(reward)\n",
    "            output_sample = torch.from_numpy(observation.reshape((1, -1))).float()\n",
    "            memory.push(input_sample, torch.tensor([[action.item()]]), output_sample, torch.tensor([reward]))\n",
    "            if (terminated or truncated) and not ignore_done:\n",
    "                break\n",
    "        episode_rewards.append(np.sum(rewards))\n",
    "\n",
    "    # Get the average reward over all episodes\n",
    "    fitness = episode_rewards\n",
    "    if render:\n",
    "        return fitness, memory, frames\n",
    "    return fitness, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USED TO STORE THE EXPERIMENT DICTIONARY\n",
    "import inspect\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "\n",
    "def serialize_functions_in_dict(dictionary):\n",
    "    for key, value in dictionary.items():\n",
    "        if inspect.isfunction(value) or inspect.ismethod(value):\n",
    "            dictionary[key] = value.__name__\n",
    "        elif isinstance(value, list):\n",
    "            for i, item in enumerate(value):\n",
    "                if isinstance(item, dict):\n",
    "                    value[i] = serialize_functions_in_dict(item)\n",
    "                elif inspect.isfunction(item) or inspect.ismethod(item):\n",
    "                    value[i] = item.__name__\n",
    "                elif isinstance(item, Node):\n",
    "                    value[i] = item.symb\n",
    "        elif isinstance(value, dict):\n",
    "            dictionary[key] = serialize_functions_in_dict(value)\n",
    "    return dictionary\n",
    "\n",
    "### USED TO CREATE THE EXPERIMENT DICTIONARY\n",
    "def grid_search_params(params_dict):\n",
    "    \"\"\"\n",
    "    Given a dictionary of hyperparameters, if a value is a list, loop over all values\n",
    "    and create a grid search.\n",
    "    \"\"\"\n",
    "    param_keys = params_dict.keys()\n",
    "    param_values = params_dict.values()\n",
    "    param_combinations = list(itertools.product(*[v if isinstance(v, list) else [v] for v in param_values]))\n",
    "    for combination in param_combinations:\n",
    "        yield dict(zip(param_keys, combination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the gen as a pickle file in the gens folder\n",
    "def save_and_evaluate_evo_generations(evo, fitness_function, experiment_name, num_episodes=10):\n",
    "    generation_evo_fitnesses = []\n",
    "    generation_test_fitnesses = []\n",
    "    for i, gen in enumerate(evo.best_of_gens):\n",
    "        episode_rewards, _ = fitness_function(gen, num_episodes=num_episodes)\n",
    "        evo_fitness_mean, evo_fitness_std = round(np.mean(gen.fitnesses), 3), round(np.std(gen.fitnesses), 3)\n",
    "        test_fitness_mean, test_fitness_std  = round(np.mean(episode_rewards), 3), round(np.std(episode_rewards), 3)\n",
    "        print(f\"Best of Generation {i}: evo fitness:{evo_fitness_mean}+/-{evo_fitness_std} \\t test_fitness:{test_fitness_mean}+/-{test_fitness_std}\")\n",
    "        generation_evo_fitnesses.append(gen.fitnesses)\n",
    "        generation_test_fitnesses.append(episode_rewards)\n",
    "        # create the gens folder if it doesn't exist\n",
    "        with open(f\"./experiments/{experiment_name}/gen_{i}_{evo_fitness_mean}_{test_fitness_mean}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(gen, f)\n",
    "\n",
    "    np.save(f\"./experiments/{experiment_name}/generation_evo_fitnesses.npy\", generation_evo_fitnesses)\n",
    "    np.save(f\"./experiments/{experiment_name}/generation_test_fitnesses.npy\", generation_test_fitnesses)\n",
    "   \n",
    "    return generation_evo_fitnesses, generation_test_fitnesses\n",
    "\n",
    "def plot_evo_test_fitnesses(evo_fitnesses, test_fitnesses, experiment_name):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.set_title(f\"Fitnesses: {experiment_name}\")\n",
    "    ax.set_xlabel(\"Generation\")\n",
    "    ax.set_ylabel(\"Fitness\")\n",
    "    ax.plot(np.arange(len(evo_fitnesses)), [np.mean(gen) for gen in evo_fitnesses], label=\"evo_fitness\", color='tab:blue')\n",
    "    ax.fill_between(np.arange(len(evo_fitnesses)), [np.mean(gen) - np.std(gen) for gen in evo_fitnesses], [np.mean(gen) + np.std(gen) for gen in evo_fitnesses], alpha=0.2, color='tab:blue')\n",
    "    ax.plot(np.arange(len(test_fitnesses)), [np.mean(gen) for gen in test_fitnesses], label=\"test_fitness\", color='tab:orange')\n",
    "    ax.fill_between(np.arange(len(test_fitnesses)), [np.mean(gen) - np.std(gen) for gen in test_fitnesses], [np.mean(gen) + np.std(gen) for gen in test_fitnesses], alpha=0.2, color='tab:orange')\n",
    "    ax.legend()\n",
    "    plt.savefig(f\"./experiments/{experiment_name}/{experiment_name}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.2}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.5}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.2}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.5}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.2}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.5}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "{'fitness_function': 'fitness_function_pt', 'internal_nodes': ['+', '-', '*', '/'], 'leaf_nodes': ['x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'const?'], 'n_trees': 4, 'pop_size': 64, 'max_gens': 50, 'init_max_depth': 4, 'max_tree_size': 32, 'crossovers': [{'fun': 'subtree_crossover', 'rate': 0.8}], 'mutations': [{'fun': 'subtree_mutation', 'rate': 0.8}], 'coeff_opts': [{'fun': 'coeff_mutation', 'rate': 0.8}], 'selection': {'fun': 'tournament_selection', 'kwargs': {'tournament_size': 8}}, 'n_jobs': 8, 'verbose': True}\n",
      "gen: 1,\tbest of gen fitness: -80.374+/-61.302,\tbest of gen size: 27\n",
      "gen: 2,\tbest of gen fitness: -85.375+/-77.205,\tbest of gen size: 25\n",
      "gen: 3,\tbest of gen fitness: -91.180+/-48.230,\tbest of gen size: 25\n",
      "gen: 4,\tbest of gen fitness: -73.602+/-69.779,\tbest of gen size: 29\n",
      "gen: 5,\tbest of gen fitness: -88.705+/-65.789,\tbest of gen size: 27\n",
      "gen: 6,\tbest of gen fitness: -59.663+/-113.810,\tbest of gen size: 27\n",
      "gen: 7,\tbest of gen fitness: -91.280+/-28.410,\tbest of gen size: 29\n",
      "gen: 8,\tbest of gen fitness: -89.348+/-69.343,\tbest of gen size: 27\n",
      "gen: 9,\tbest of gen fitness: -75.460+/-61.946,\tbest of gen size: 29\n",
      "gen: 10,\tbest of gen fitness: -68.457+/-80.797,\tbest of gen size: 27\n",
      "gen: 11,\tbest of gen fitness: -77.038+/-61.826,\tbest of gen size: 27\n",
      "gen: 12,\tbest of gen fitness: -82.364+/-49.634,\tbest of gen size: 25\n",
      "gen: 13,\tbest of gen fitness: -101.776+/-44.812,\tbest of gen size: 25\n",
      "gen: 14,\tbest of gen fitness: -83.559+/-48.141,\tbest of gen size: 27\n",
      "gen: 15,\tbest of gen fitness: -84.376+/-58.577,\tbest of gen size: 31\n",
      "gen: 16,\tbest of gen fitness: -82.810+/-77.872,\tbest of gen size: 27\n",
      "gen: 17,\tbest of gen fitness: -73.074+/-29.527,\tbest of gen size: 25\n",
      "gen: 18,\tbest of gen fitness: -83.586+/-69.791,\tbest of gen size: 27\n",
      "gen: 19,\tbest of gen fitness: -81.952+/-57.855,\tbest of gen size: 25\n",
      "gen: 20,\tbest of gen fitness: -79.877+/-39.683,\tbest of gen size: 29\n",
      "gen: 21,\tbest of gen fitness: -58.348+/-50.421,\tbest of gen size: 29\n",
      "gen: 22,\tbest of gen fitness: -89.640+/-48.622,\tbest of gen size: 31\n",
      "gen: 23,\tbest of gen fitness: -85.876+/-47.972,\tbest of gen size: 29\n",
      "gen: 24,\tbest of gen fitness: -90.340+/-57.452,\tbest of gen size: 29\n",
      "gen: 25,\tbest of gen fitness: -67.458+/-63.625,\tbest of gen size: 21\n",
      "gen: 26,\tbest of gen fitness: -82.890+/-45.702,\tbest of gen size: 29\n",
      "gen: 27,\tbest of gen fitness: -64.711+/-17.674,\tbest of gen size: 29\n",
      "gen: 28,\tbest of gen fitness: -31.926+/-102.883,\tbest of gen size: 29\n",
      "gen: 29,\tbest of gen fitness: -63.889+/-63.155,\tbest of gen size: 29\n",
      "gen: 30,\tbest of gen fitness: -72.789+/-40.454,\tbest of gen size: 29\n",
      "gen: 31,\tbest of gen fitness: -35.174+/-92.088,\tbest of gen size: 29\n",
      "gen: 32,\tbest of gen fitness: -30.583+/-101.453,\tbest of gen size: 29\n",
      "gen: 33,\tbest of gen fitness: -44.497+/-49.925,\tbest of gen size: 29\n",
      "gen: 34,\tbest of gen fitness: -28.982+/-108.412,\tbest of gen size: 29\n",
      "gen: 35,\tbest of gen fitness: -28.477+/-81.896,\tbest of gen size: 29\n",
      "gen: 36,\tbest of gen fitness: -42.212+/-10.304,\tbest of gen size: 29\n",
      "gen: 37,\tbest of gen fitness: -6.017+/-94.488,\tbest of gen size: 29\n",
      "gen: 38,\tbest of gen fitness: -4.870+/-149.061,\tbest of gen size: 29\n",
      "gen: 39,\tbest of gen fitness: -18.685+/-56.405,\tbest of gen size: 29\n",
      "gen: 40,\tbest of gen fitness: 70.426+/-69.361,\tbest of gen size: 29\n",
      "gen: 41,\tbest of gen fitness: 23.443+/-91.391,\tbest of gen size: 29\n",
      "gen: 42,\tbest of gen fitness: 21.392+/-60.513,\tbest of gen size: 29\n",
      "gen: 43,\tbest of gen fitness: 22.954+/-141.532,\tbest of gen size: 29\n",
      "gen: 44,\tbest of gen fitness: 18.260+/-98.374,\tbest of gen size: 29\n",
      "gen: 45,\tbest of gen fitness: 11.823+/-86.782,\tbest of gen size: 29\n",
      "gen: 46,\tbest of gen fitness: 39.050+/-108.340,\tbest of gen size: 29\n",
      "gen: 47,\tbest of gen fitness: 18.611+/-83.311,\tbest of gen size: 29\n",
      "gen: 48,\tbest of gen fitness: 46.411+/-106.014,\tbest of gen size: 29\n",
      "gen: 49,\tbest of gen fitness: 21.583+/-134.595,\tbest of gen size: 29\n",
      "gen: 50,\tbest of gen fitness: 20.938+/-69.255,\tbest of gen size: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\miniconda3\\envs\\genepromulti\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best of Generation 0: evo fitness:-83.028+/-62.824 \t test_fitness:-368.708+/-178.318\n",
      "Best of Generation 1: evo fitness:-80.374+/-61.302 \t test_fitness:-121.794+/-79.605\n",
      "Best of Generation 2: evo fitness:-85.375+/-77.205 \t test_fitness:-146.729+/-15.273\n",
      "Best of Generation 3: evo fitness:-91.18+/-48.23 \t test_fitness:-95.576+/-27.072\n",
      "Best of Generation 4: evo fitness:-73.602+/-69.779 \t test_fitness:-125.242+/-42.806\n",
      "Best of Generation 5: evo fitness:-88.705+/-65.789 \t test_fitness:-133.624+/-21.684\n",
      "Best of Generation 6: evo fitness:-59.663+/-113.81 \t test_fitness:-124.911+/-49.621\n",
      "Best of Generation 7: evo fitness:-91.28+/-28.41 \t test_fitness:-167.472+/-49.112\n",
      "Best of Generation 8: evo fitness:-89.348+/-69.343 \t test_fitness:-156.884+/-49.372\n",
      "Best of Generation 9: evo fitness:-75.46+/-61.946 \t test_fitness:-151.197+/-30.037\n",
      "Best of Generation 10: evo fitness:-68.457+/-80.797 \t test_fitness:-99.262+/-42.196\n",
      "Best of Generation 11: evo fitness:-77.038+/-61.826 \t test_fitness:-110.96+/-18.375\n",
      "Best of Generation 12: evo fitness:-82.364+/-49.634 \t test_fitness:-344.886+/-430.405\n",
      "Best of Generation 13: evo fitness:-101.776+/-44.812 \t test_fitness:-105.838+/-20.176\n",
      "Best of Generation 14: evo fitness:-83.559+/-48.141 \t test_fitness:-105.896+/-68.914\n",
      "Best of Generation 15: evo fitness:-84.376+/-58.577 \t test_fitness:-124.731+/-16.9\n",
      "Best of Generation 16: evo fitness:-82.81+/-77.872 \t test_fitness:-117.759+/-52.709\n",
      "Best of Generation 17: evo fitness:-73.074+/-29.527 \t test_fitness:-120.785+/-17.936\n",
      "Best of Generation 18: evo fitness:-83.586+/-69.791 \t test_fitness:-131.634+/-26.939\n",
      "Best of Generation 19: evo fitness:-81.952+/-57.855 \t test_fitness:-150.942+/-65.167\n",
      "Best of Generation 20: evo fitness:-79.877+/-39.683 \t test_fitness:-141.067+/-15.454\n",
      "Best of Generation 21: evo fitness:-58.348+/-50.421 \t test_fitness:-222.152+/-136.178\n",
      "Best of Generation 22: evo fitness:-89.64+/-48.622 \t test_fitness:-144.845+/-10.831\n",
      "Best of Generation 23: evo fitness:-85.876+/-47.972 \t test_fitness:-125.002+/-21.826\n",
      "Best of Generation 24: evo fitness:-90.34+/-57.452 \t test_fitness:-107.117+/-50.472\n",
      "Best of Generation 25: evo fitness:-67.458+/-63.625 \t test_fitness:-112.085+/-41.968\n",
      "Best of Generation 26: evo fitness:-82.89+/-45.702 \t test_fitness:-113.073+/-9.72\n",
      "Best of Generation 27: evo fitness:-64.711+/-17.674 \t test_fitness:-222.825+/-211.523\n",
      "Best of Generation 28: evo fitness:-31.926+/-102.883 \t test_fitness:-133.312+/-16.054\n",
      "Best of Generation 29: evo fitness:-63.889+/-63.155 \t test_fitness:-120.03+/-65.65\n",
      "Best of Generation 30: evo fitness:-72.789+/-40.454 \t test_fitness:-113.029+/-36.441\n",
      "Best of Generation 31: evo fitness:-35.174+/-92.088 \t test_fitness:-138.936+/-30.984\n",
      "Best of Generation 32: evo fitness:-30.583+/-101.453 \t test_fitness:-148.965+/-21.3\n",
      "Best of Generation 33: evo fitness:-44.497+/-49.925 \t test_fitness:-56.441+/-62.454\n",
      "Best of Generation 34: evo fitness:-28.982+/-108.412 \t test_fitness:-98.508+/-42.755\n",
      "Best of Generation 35: evo fitness:-28.477+/-81.896 \t test_fitness:-117.183+/-45.268\n",
      "Best of Generation 36: evo fitness:-42.212+/-10.304 \t test_fitness:-79.506+/-40.997\n",
      "Best of Generation 37: evo fitness:-6.017+/-94.488 \t test_fitness:-151.68+/-29.574\n",
      "Best of Generation 38: evo fitness:-4.87+/-149.061 \t test_fitness:-110.949+/-41.442\n",
      "Best of Generation 39: evo fitness:-18.685+/-56.405 \t test_fitness:-59.054+/-69.387\n",
      "Best of Generation 40: evo fitness:70.426+/-69.361 \t test_fitness:-99.477+/-229.276\n",
      "Best of Generation 41: evo fitness:23.443+/-91.391 \t test_fitness:-66.96+/-61.611\n",
      "Best of Generation 42: evo fitness:21.392+/-60.513 \t test_fitness:-109.723+/-77.853\n",
      "Best of Generation 43: evo fitness:22.954+/-141.532 \t test_fitness:-78.531+/-150.494\n",
      "Best of Generation 44: evo fitness:18.26+/-98.374 \t test_fitness:-83.845+/-46.74\n",
      "Best of Generation 45: evo fitness:11.823+/-86.782 \t test_fitness:-97.206+/-67.729\n",
      "Best of Generation 46: evo fitness:39.05+/-108.34 \t test_fitness:-137.228+/-80.133\n",
      "Best of Generation 47: evo fitness:18.611+/-83.311 \t test_fitness:-109.019+/-81.355\n",
      "Best of Generation 48: evo fitness:46.411+/-106.014 \t test_fitness:5.155+/-9.022\n",
      "Best of Generation 49: evo fitness:21.583+/-134.595 \t test_fitness:-157.939+/-118.466\n",
      "Best of Generation 50: evo fitness:20.938+/-69.255 \t test_fitness:-96.005+/-39.676\n",
      "gen: 1,\tbest of gen fitness: -91.618+/-26.994,\tbest of gen size: 23\n",
      "gen: 2,\tbest of gen fitness: -85.246+/-50.299,\tbest of gen size: 23\n",
      "gen: 3,\tbest of gen fitness: -101.599+/-5.307,\tbest of gen size: 23\n",
      "gen: 4,\tbest of gen fitness: -101.585+/-38.965,\tbest of gen size: 23\n",
      "gen: 5,\tbest of gen fitness: -101.485+/-11.222,\tbest of gen size: 23\n",
      "gen: 6,\tbest of gen fitness: -100.038+/-14.469,\tbest of gen size: 23\n",
      "gen: 7,\tbest of gen fitness: -100.986+/-9.163,\tbest of gen size: 29\n",
      "gen: 8,\tbest of gen fitness: -98.760+/-27.857,\tbest of gen size: 29\n",
      "gen: 9,\tbest of gen fitness: -100.368+/-16.446,\tbest of gen size: 23\n",
      "gen: 10,\tbest of gen fitness: -87.140+/-69.827,\tbest of gen size: 23\n",
      "gen: 11,\tbest of gen fitness: -94.573+/-12.269,\tbest of gen size: 29\n",
      "gen: 12,\tbest of gen fitness: -29.735+/-128.565,\tbest of gen size: 23\n",
      "gen: 13,\tbest of gen fitness: -12.268+/-55.061,\tbest of gen size: 23\n",
      "gen: 14,\tbest of gen fitness: 3.781+/-107.398,\tbest of gen size: 25\n",
      "gen: 15,\tbest of gen fitness: 82.438+/-148.251,\tbest of gen size: 23\n",
      "gen: 16,\tbest of gen fitness: -11.496+/-33.356,\tbest of gen size: 23\n",
      "gen: 17,\tbest of gen fitness: 24.193+/-95.799,\tbest of gen size: 31\n",
      "gen: 18,\tbest of gen fitness: 34.376+/-91.755,\tbest of gen size: 23\n",
      "gen: 19,\tbest of gen fitness: 40.762+/-80.443,\tbest of gen size: 31\n",
      "gen: 20,\tbest of gen fitness: 76.942+/-131.188,\tbest of gen size: 31\n",
      "gen: 21,\tbest of gen fitness: 67.028+/-94.639,\tbest of gen size: 31\n",
      "gen: 22,\tbest of gen fitness: 58.506+/-104.274,\tbest of gen size: 31\n",
      "gen: 23,\tbest of gen fitness: 69.890+/-87.507,\tbest of gen size: 31\n",
      "gen: 24,\tbest of gen fitness: 88.986+/-118.027,\tbest of gen size: 29\n",
      "gen: 25,\tbest of gen fitness: 113.801+/-119.549,\tbest of gen size: 29\n",
      "gen: 26,\tbest of gen fitness: 76.128+/-111.893,\tbest of gen size: 31\n",
      "gen: 27,\tbest of gen fitness: 124.343+/-79.263,\tbest of gen size: 31\n",
      "gen: 28,\tbest of gen fitness: 94.337+/-127.686,\tbest of gen size: 31\n",
      "gen: 29,\tbest of gen fitness: 116.316+/-125.883,\tbest of gen size: 29\n",
      "gen: 30,\tbest of gen fitness: 150.854+/-52.324,\tbest of gen size: 29\n",
      "gen: 31,\tbest of gen fitness: 148.773+/-56.136,\tbest of gen size: 29\n",
      "gen: 32,\tbest of gen fitness: 101.217+/-89.656,\tbest of gen size: 29\n",
      "gen: 33,\tbest of gen fitness: 109.078+/-98.030,\tbest of gen size: 29\n",
      "gen: 34,\tbest of gen fitness: 113.162+/-77.379,\tbest of gen size: 29\n",
      "gen: 35,\tbest of gen fitness: 152.138+/-19.291,\tbest of gen size: 29\n",
      "gen: 36,\tbest of gen fitness: 116.556+/-129.163,\tbest of gen size: 29\n",
      "gen: 37,\tbest of gen fitness: 114.908+/-93.257,\tbest of gen size: 29\n",
      "gen: 38,\tbest of gen fitness: 145.613+/-35.936,\tbest of gen size: 29\n",
      "gen: 39,\tbest of gen fitness: 120.480+/-132.962,\tbest of gen size: 29\n",
      "gen: 40,\tbest of gen fitness: 148.137+/-39.302,\tbest of gen size: 29\n",
      "gen: 41,\tbest of gen fitness: 93.631+/-105.028,\tbest of gen size: 29\n",
      "gen: 42,\tbest of gen fitness: 113.640+/-122.402,\tbest of gen size: 29\n",
      "gen: 43,\tbest of gen fitness: 98.405+/-86.779,\tbest of gen size: 29\n",
      "gen: 44,\tbest of gen fitness: 115.521+/-110.278,\tbest of gen size: 29\n",
      "gen: 45,\tbest of gen fitness: 102.782+/-108.501,\tbest of gen size: 29\n",
      "gen: 46,\tbest of gen fitness: 112.778+/-104.638,\tbest of gen size: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\miniconda3\\envs\\genepromulti\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen: 47,\tbest of gen fitness: 150.756+/-15.237,\tbest of gen size: 29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m         generation_evo_fitnesses, generation_test_fitnesses \u001b[39m=\u001b[39m save_and_evaluate_evo_generations(evo_baseline, fitness_function_pt, specific_experiment_name, num_episodes\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m     45\u001b[0m         plot_evo_test_fitnesses(generation_evo_fitnesses, generation_test_fitnesses, specific_experiment_name)\n\u001b[1;32m---> 47\u001b[0m hpo_evolve(evo_settings, experiment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbaseline\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[8], line 39\u001b[0m, in \u001b[0;36mhpo_evolve\u001b[1;34m(evo_settings, experiment_name)\u001b[0m\n\u001b[0;32m     36\u001b[0m     json\u001b[39m.\u001b[39mdump(serialized_dict, f)\n\u001b[0;32m     38\u001b[0m evo_baseline \u001b[39m=\u001b[39m Evolution(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39msettings)\n\u001b[1;32m---> 39\u001b[0m evo_baseline\u001b[39m.\u001b[39;49mevolve()\n\u001b[0;32m     41\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./experiments/\u001b[39m\u001b[39m{\u001b[39;00mspecific_experiment_name\u001b[39m}\u001b[39;00m\u001b[39m/evolution_class.pickle\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     42\u001b[0m     pickle\u001b[39m.\u001b[39mdump(evo_baseline, f)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\genepromulti\\genepro\\evo.py:244\u001b[0m, in \u001b[0;36mEvolution.evolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39m# generational loop\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_must_terminate():\n\u001b[0;32m    243\u001b[0m   \u001b[39m# perform one generation\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_perform_generation()\n\u001b[0;32m    245\u001b[0m   \u001b[39m# log info\u001b[39;00m\n\u001b[0;32m    246\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\genepromulti\\genepro\\evo.py:205\u001b[0m, in \u001b[0;36mEvolution._perform_generation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m offspring_population \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(delayed(generate_offspring)\n\u001b[0;32m    199\u001b[0m   (t, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrossovers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoeff_opts, \n\u001b[0;32m    200\u001b[0m   parents, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minternal_nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleaf_nodes,\n\u001b[0;32m    201\u001b[0m   constraints\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_tree_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_tree_size}) \n\u001b[0;32m    202\u001b[0m   \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m parents)\n\u001b[0;32m    204\u001b[0m \u001b[39m# evaluate each offspring and store its fitness \u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m fitnesses \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness_function)(t) \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m offspring_population)\n\u001b[0;32m    206\u001b[0m fitnesses \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfitnesses)))\n\u001b[0;32m    207\u001b[0m memories \u001b[39m=\u001b[39m fitnesses[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\genepromulti\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\genepromulti\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\genepromulti\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\genepromulti\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\genepromulti\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "from genepro.selection import tournament_selection\n",
    "from genepro.variation import coeff_mutation, subtree_crossover, subtree_mutation\n",
    "\n",
    "experiment_name = \"baseline\"\n",
    "num_features = env.observation_space.shape[0]\n",
    "evo_settings = {\n",
    "    \"fitness_function\": fitness_function_pt,\n",
    "    \"internal_nodes\": [[Plus(), Minus(), Times(), Div()]],\n",
    "    \"leaf_nodes\": [[Feature(i) for i in range(num_features)] + [Constant()]],\n",
    "    \"n_trees\": 4,\n",
    "    \"pop_size\": 64,\n",
    "    \"max_gens\": 50,\n",
    "    \"init_max_depth\": 4,\n",
    "    \"max_tree_size\": 32,\n",
    "    \"crossovers\": [[{\"fun\": subtree_crossover, \"rate\": 0.2}], [{\"fun\": subtree_crossover, \"rate\": 0.5}], [{\"fun\": subtree_crossover, \"rate\": 0.8}]],\n",
    "    \"mutations\": [[{\"fun\": subtree_mutation, \"rate\": 0.2}], [{\"fun\": subtree_mutation, \"rate\": 0.5}], [{\"fun\": subtree_mutation, \"rate\": 0.8}]],\n",
    "    \"coeff_opts\": [[{\"fun\": coeff_mutation, \"rate\": 0.2}], [{\"fun\": coeff_mutation, \"rate\": 0.5}], [{\"fun\": coeff_mutation, \"rate\": 0.8}]],\n",
    "    \"selection\": {\"fun\": tournament_selection, \"kwargs\": {\"tournament_size\": 8}},\n",
    "    \"n_jobs\": 8,\n",
    "    \"verbose\": True\n",
    "}\n",
    "\n",
    "def hpo_evolve(evo_settings, experiment_name):\n",
    "    hpo_settings = list(grid_search_params(evo_settings))\n",
    "    for settings in hpo_settings:\n",
    "        serialized_dict = serialize_functions_in_dict(deepcopy(settings))\n",
    "        print(serialized_dict)\n",
    "        \n",
    "    for i, settings in enumerate(hpo_settings):\n",
    "        specific_experiment_name = experiment_name + f\"_pops{settings['pop_size']}_gens{settings['max_gens']}_mts{settings['max_tree_size']}_cor{settings['crossovers'][0]['rate']}_mutr{settings['mutations'][0]['rate']}_coeffr{settings['coeff_opts'][0]['rate']}\"\n",
    "        os.makedirs(f\"./experiments/{specific_experiment_name}\", exist_ok=True)\n",
    "        with open(f\"./experiments/{specific_experiment_name}/evo_settings.json\", \"w\") as f:\n",
    "            serialized_dict = serialize_functions_in_dict(deepcopy(settings))\n",
    "            json.dump(serialized_dict, f)\n",
    "\n",
    "        evo_baseline = Evolution(**settings)\n",
    "        evo_baseline.evolve()\n",
    "\n",
    "        with open(f\"./experiments/{specific_experiment_name}/evolution_class.pickle\", \"wb\") as f:\n",
    "            pickle.dump(evo_baseline, f)\n",
    "        \n",
    "        generation_evo_fitnesses, generation_test_fitnesses = save_and_evaluate_evo_generations(evo_baseline, fitness_function_pt, specific_experiment_name, num_episodes=5)\n",
    "        plot_evo_test_fitnesses(generation_evo_fitnesses, generation_test_fitnesses, specific_experiment_name)\n",
    "        \n",
    "hpo_evolve(evo_settings, experiment_name=\"baseline\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run multiple experiments and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_EXPERIMENTS = 2\n",
    "# SAVE_DIR = \"./plots/plot_data\"\n",
    "# experiment_name = \"plot_test\"\n",
    "\n",
    "# evo_settings = {\n",
    "#     \"fitness_function\": fitness_function_pt,\n",
    "#     \"internal_nodes\": [Plus(), Minus(), Times(), Div()],\n",
    "#     \"leaf_nodes\": [Feature(i) for i in range(num_features)] + [Constant()],\n",
    "#     \"n_trees\": 4,\n",
    "#     \"pop_size\": 8,\n",
    "#     \"max_gens\": 10,\n",
    "#     \"init_max_depth\": 4,\n",
    "#     \"max_tree_size\": 32,\n",
    "#     \"crossovers\": [{\"fun\": subtree_crossover, \"rate\": 0.5}],\n",
    "#     \"mutations\": [{\"fun\": subtree_mutation, \"rate\": 0.5}],\n",
    "#     \"coeff_opts\": [{\"fun\": coeff_mutation, \"rate\": 0.5}],\n",
    "#     \"selection\": {\"fun\": tournament_selection, \"kwargs\": {\"tournament_size\": 8}},\n",
    "#     \"n_jobs\": 8,\n",
    "#     \"verbose\": True\n",
    "# }\n",
    "\n",
    "# os.makedirs(f\"./experiments/{experiment_name}\", exist_ok=True)\n",
    "# with open(f\"./experiments/{experiment_name}/evo_settings.json\", \"w\") as f:\n",
    "#     serialized_dict = serialize_functions_in_dict(deepcopy(evo_settings))\n",
    "#     json.dump(serialized_dict, f)\n",
    "\n",
    "# def run_multiple_evolutions(num_experiments, save_path):\n",
    "#     fitnesses = []\n",
    "    \n",
    "#     for _ in range(num_experiments):\n",
    "#         evo_baseline = Evolution(**evo_settings)\n",
    "#         evo_baseline.evolve()\n",
    "#         fitness = save_and_evaluate_evo_generations(evo_baseline, fitness_function_pt)\n",
    "#         fitnesses.append(fitness)\n",
    "    \n",
    "#     np.save(save_path, fitnesses)\n",
    "\n",
    "# save_path = f\"{SAVE_DIR}/{experiment_name}.npy\"\n",
    "\n",
    "# run_multiple_evolutions(NUM_EXPERIMENTS, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve\n",
    "Running this cell will use all the settings above as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path=\"./\", filename=\"evolved_lander.gif\"):\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval=50)\n",
    "    anim.save(path + filename, writer=\"imagemagick\", fps=60)\n",
    "\n",
    "\n",
    "frames = []\n",
    "avg_fitness, frames = get_test_score(evo.best_of_gens[-1], num_episodes=5, episode_duration=300, seed=5, render=True)\n",
    "print(\"Average fitness of the render is: \", avg_fitness)\n",
    "env.close()\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "GAMMA = 0.99\n",
    "\n",
    "constants = best.get_subtrees_consts()\n",
    "\n",
    "if len(constants) > 0:\n",
    "    optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "for _ in range(500):\n",
    "    if len(constants) > 0 and len(evo.memory) > batch_size:\n",
    "        target_tree = copy.deepcopy(best)\n",
    "\n",
    "        transitions = evo.memory.sample(batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        non_final_mask = torch.tensor(\n",
    "            tuple(map(lambda s: s is not None, batch.next_state)), dtype=torch.bool\n",
    "        )\n",
    "\n",
    "        non_final_next_states = torch.cat(\n",
    "            [s for s in batch.next_state if s is not None]\n",
    "        )\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "        next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = (\n",
    "                target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "            )\n",
    "\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "        optimizer.step()\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "fitness_function_pt(\n",
    "    best, num_episodes=1, episode_duration=500, render=True, ignore_done=False\n",
    ")\n",
    "env.close()\n",
    "save_frames_as_gif(frames, filename=\"evolved_lander_RL.gif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
